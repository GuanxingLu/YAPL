# Learn from Video (LfV)

* **[arXiv:2404]** Towards Generalist Robot Learning from Internet Video: A Survey

* **[arxiv:2406]** Dreamitate: Real-World Visuomotor Policy Learning via Video Generation, Shuran Song
> CAD to track and execute

* **[arXiv:2402]** Video as the New Language for Real-World Decision Making, Sherry Yang

* **[RSS'24]** Universal Manipulation Interfaceï¼šIn-The-Wild Robot Teaching Without In-The-Wild Robots
> Learn from robotic videos. Tracking + SLAM

* **[CoRL'23]** MimicGen: A Data Generation System for Scalable Robot Learning using Human Demonstrations
> Subtask segment + Hardcoded augmentation

* **[arXiv:2405]** ORION: Vision-based Manipulation from Single Human Video with Open-World Object Graph
> Open-world object graphs

* **[CoRL'23]** MimicPlay: Long-Horizon Imitation Learning by Watching Human Play
> Large human video -> latent plan, GMM decoder + small robot data

* **[]** Robot Utility Models General Policies for Zero-Shot Deployment in New Environments
> Stick v2 gripper collection system.

# World Model

* **[NeurIPS'18 Oral]** Recurrent World Models Facilitate Policy Evolution

* **[ICCV'21]** Pathdreamer: A World Model for Indoor Navigation
> Observations also include depth and segmentations.

* **[ICLR'24 Outstanding]** Learning Interactive Real-World Simulators
> UniSim, given o_{t-1} and a_{t-1), predict o_t

* **[NeurIPS'19]** Learning to Predict Without Looking Ahead: World Models Without Forward Prediction
> A world model can be quite wrong, so long as it is wrong in the right way

* **[ECCV'24]** OccWorld: Learning a 3D Occupancy World Model for Autonomous Driving
> A 3D occupancy scene tokenizer + GPT-2, W(y^T, ..., y^T-t ; p^T, ..., p^T-t) = y^T+1, p^T+1

* **[arXiv:2408]** DIFFUSION MODELS ARE REAL-TIME GAME ENGINES
> 20 FPS, Diffusion on RL collections, ~30 PSNR. Noise augmentation to achieve auto-regressive generation.

* **[SIGGRAPH'22]** Physics-based Character Controllers Using Conditional VAEs
> World Model for motion generation.

* **[Siggraph Asia'22]** ControlVAE: Model-Based Learning of Generative Controllers for Physics-Based Characters
> World Model for motion generation.

